{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7584258,"sourceType":"datasetVersion","datasetId":4414808},{"sourceId":4298,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3093}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##this notebook contains my approach to setting up a second version of my solution in the \n\n##workflow in this notebook is as follow\n\n#set up llm\n\n#load up files for RAG SET UP\n\n#Set up RAG\n\n#clean docs\n\n#use both character and recurrig character splitter\n\n#encode with default\n\n#use llama\n\n#Set up Question and answer parsing process\n\n#create a submission","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install transformers==4.33.0 accelerate==0.22.0 einops==0.6.1 langchain xformers==0.0.21 bitsandbytes==0.41.1 sentence_transformers==2.2.2 chromadb==0.4.12\nfrom transformers import BitsAndBytesConfig, AutoConfig, AutoTokenizer, pipeline, AutoModelForCausalLM\nfrom torch import cuda, bfloat16\nimport torch\nfrom time import time\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.document_loaders import PyPDFDirectoryLoader\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:44:51.816197Z","iopub.execute_input":"2024-03-03T19:44:51.816553Z","iopub.status.idle":"2024-03-03T19:48:33.443138Z","shell.execute_reply.started":"2024-03-03T19:44:51.816524Z","shell.execute_reply":"2024-03-03T19:48:33.441938Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting transformers==4.33.0\n  Downloading transformers-4.33.0-py3-none-any.whl.metadata (119 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate==0.22.0\n  Downloading accelerate-0.22.0-py3-none-any.whl.metadata (17 kB)\nCollecting einops==0.6.1\n  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\nCollecting langchain\n  Downloading langchain-0.1.10-py3-none-any.whl.metadata (13 kB)\nCollecting xformers==0.0.21\n  Downloading xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes==0.41.1\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\nCollecting sentence_transformers==2.2.2\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting chromadb==0.4.12\n  Downloading chromadb-0.4.12-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2.31.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.0)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (2.1.2)\nCollecting torch>=1.10.0 (from accelerate==0.22.0)\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.16.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.2.0)\nCollecting pydantic<2.0,>=1.9 (from chromadb==0.4.12)\n  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.2/150.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting chroma-hnswlib==0.7.3 (from chromadb==0.4.12)\n  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nCollecting fastapi<0.100.0,>=0.95.2 (from chromadb==0.4.12)\n  Downloading fastapi-0.99.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.25.0)\nCollecting posthog>=2.4.0 (from chromadb==0.4.12)\n  Downloading posthog-3.4.2-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (4.9.0)\nCollecting pulsar-client>=3.1.0 (from chromadb==0.4.12)\n  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb==0.4.12)\n  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nCollecting pypika>=0.48.9 (from chromadb==0.4.12)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (7.4.0)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (6.1.1)\nCollecting bcrypt>=4.0.1 (from chromadb==0.4.12)\n  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (0.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.1.2)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.0.0 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (69.0.3)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (0.42.0)\nCollecting cmake (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n  Downloading cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\nCollecting lit (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n  Downloading lit-17.0.6.tar.gz (153 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nCollecting langchain-community<0.1,>=0.0.25 (from langchain)\n  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\nCollecting langchain-core<0.2,>=0.1.28 (from langchain)\n  Downloading langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\nCollecting langsmith<0.2.0,>=0.1.0 (from langchain)\n  Downloading langsmith-0.1.13-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nCollecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb==0.4.12)\n  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0) (2024.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.28->langchain) (4.2.0)\nCollecting packaging>=20.0 (from transformers==4.33.0)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain)\n  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.12)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (3.20.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (1.16.0)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.12)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.2.1)\nRequirement already satisfied: python-dateutil>2.1 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.8.2)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb==0.4.12) (2024.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (1.26.18)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.4.12) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (1.0.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (12.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers==2.2.2) (9.5.0)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.28->langchain) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.28->langchain) (1.2.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.12)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.22.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.22.0) (1.3.0)\nDownloading transformers-4.33.0-py3-none-any.whl (7.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl (167.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chromadb-0.4.12-py3-none-any.whl (426 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.5/426.5 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.1.10-py3-none-any.whl (806 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.2/806.2 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\nDownloading langsmith-0.1.13-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-3.4.2-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading starlette-0.27.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: sentence_transformers, pypika, lit\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=659171f4de6c85b96e336de80f56cf23bb0b0a6b610932dbdd30edb21f280bf3\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=1771f3d32d11356790ab398893621110743b4fff9790b525777d37bc4c244b91\n  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=a6d9fe09bee581c0bcc61f1cd9ccf89b107692399f57a0766c10a62321800e2c\n  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\nSuccessfully built sentence_transformers pypika lit\nInstalling collected packages: tokenizers, pypika, monotonic, lit, cmake, bitsandbytes, pydantic, pulsar-client, packaging, orjson, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, humanfriendly, einops, chroma-hnswlib, bcrypt, starlette, posthog, nvidia-cusolver-cu11, nvidia-cudnn-cu11, langsmith, coloredlogs, transformers, onnxruntime, langchain-core, fastapi, langchain-text-splitters, langchain-community, chromadb, langchain, triton, torch, xformers, sentence_transformers, accelerate\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.5.3\n    Uninstalling pydantic-2.5.3:\n      Successfully uninstalled pydantic-2.5.3\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n  Attempting uninstall: starlette\n    Found existing installation: starlette 0.32.0.post1\n    Uninstalling starlette-0.32.0.post1:\n      Successfully uninstalled starlette-0.32.0.post1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.1\n    Uninstalling transformers-4.38.1:\n      Successfully uninstalled transformers-4.38.1\n  Attempting uninstall: fastapi\n    Found existing installation: fastapi 0.108.0\n    Uninstalling fastapi-0.108.0:\n      Successfully uninstalled fastapi-0.108.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.27.2\n    Uninstalling accelerate-0.27.2:\n      Successfully uninstalled accelerate-0.27.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.33.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.14 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.22.0 bcrypt-4.1.2 bitsandbytes-0.41.1 chroma-hnswlib-0.7.3 chromadb-0.4.12 cmake-3.28.3 coloredlogs-15.0.1 einops-0.6.1 fastapi-0.99.1 humanfriendly-10.0 langchain-0.1.10 langchain-community-0.0.25 langchain-core-0.1.28 langchain-text-splitters-0.0.1 langsmith-0.1.13 lit-17.0.6 monotonic-1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 onnxruntime-1.17.1 orjson-3.9.15 packaging-23.2 posthog-3.4.2 pulsar-client-3.4.0 pydantic-1.10.14 pypika-0.48.9 sentence_transformers-2.2.2 starlette-0.27.0 tokenizers-0.13.3 torch-2.0.1 transformers-4.33.0 triton-2.0.0 xformers-0.0.21\n","output_type":"stream"},{"name":"stderr","text":"2024-03-03 19:48:17.618992: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-03 19:48:17.619105: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-03 19:48:17.751580: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"model_id = '/kaggle/input/llama-2/pytorch/7b-chat-hf/1'\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n# set quantization configuration to load large model with less GPU memory\n# this requires the `bitsandbytes` library\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=bfloat16\n)\nmodel_config = AutoConfig.from_pretrained(\n    model_id,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n    config=model_config,\n    quantization_config=bnb_config,\n    device_map='auto',\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntime_1 = time()\nquery_pipeline = pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",)\ntime_2 = time()\nprint(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:48:33.445471Z","iopub.execute_input":"2024-03-03T19:48:33.446390Z","iopub.status.idle":"2024-03-03T19:52:23.879759Z","shell.execute_reply.started":"2024-03-03T19:48:33.446346Z","shell.execute_reply":"2024-03-03T19:52:23.878805Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b981a2d5bff49889c0caefaea9c3095"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prepare pipeline: 0.0 sec.\n","output_type":"stream"}]},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=query_pipeline)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:52:23.881063Z","iopub.execute_input":"2024-03-03T19:52:23.881871Z","iopub.status.idle":"2024-03-03T19:52:23.887513Z","shell.execute_reply.started":"2024-03-03T19:52:23.881834Z","shell.execute_reply":"2024-03-03T19:52:23.886463Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"time_1 = time()\nresult = llm(prompt=\"Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\")\ntime_2 = time()\nprint(f\"Prepare Solution: {round(time_2-time_1, 3)} sec.\")\n\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:52:23.889706Z","iopub.execute_input":"2024-03-03T19:52:23.890001Z","iopub.status.idle":"2024-03-03T19:52:30.922016Z","shell.execute_reply.started":"2024-03-03T19:52:23.889977Z","shell.execute_reply":"2024-03-03T19:52:30.921113Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n  warn_deprecated(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prepare Solution: 7.022 sec.\n\nThe State of the Union address is an annual speech given by the President of the United States to a joint session of Congress, in which the President reports on the current state of the union and outlines their legislative agenda for the upcoming year.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install unstructured -qq #This will be used to load in our excel sheets (The textbooks)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:52:30.923185Z","iopub.execute_input":"2024-03-03T19:52:30.923476Z","iopub.status.idle":"2024-03-03T19:52:49.858644Z","shell.execute_reply.started":"2024-03-03T19:52:30.923451Z","shell.execute_reply":"2024-03-03T19:52:49.857375Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\nbooks_path = \"/kaggle/input/malawi-public-health-dataset/strengthening-health-systems-llm-challenge-for-integrated-disease-surveillance-and-response-in-malawi20240125-12750-1x85c8a/MWTGBookletsExcel\"\nbooklets = os.listdir(books_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:52:49.861146Z","iopub.execute_input":"2024-03-03T19:52:49.861538Z","iopub.status.idle":"2024-03-03T19:52:49.876646Z","shell.execute_reply.started":"2024-03-03T19:52:49.861501Z","shell.execute_reply":"2024-03-03T19:52:49.875718Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"booklets","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:52:49.877925Z","iopub.execute_input":"2024-03-03T19:52:49.878318Z","iopub.status.idle":"2024-03-03T19:52:49.886158Z","shell.execute_reply.started":"2024-03-03T19:52:49.878282Z","shell.execute_reply":"2024-03-03T19:52:49.885107Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['TG Booklet 2.xlsx',\n 'TG Booklet 5.xlsx',\n 'TG Booklet 6.xlsx',\n 'TG Booklet 4.xlsx',\n 'TG Booklet 3.xlsx',\n 'TG Booklet 1.xlsx']"},"metadata":{}}]},{"cell_type":"code","source":"!pip install langchain_community -qq \n\nfrom langchain_community.document_loaders import UnstructuredExcelLoader","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:52:49.887462Z","iopub.execute_input":"2024-03-03T19:52:49.887867Z","iopub.status.idle":"2024-03-03T19:53:03.113482Z","shell.execute_reply.started":"2024-03-03T19:52:49.887842Z","shell.execute_reply":"2024-03-03T19:53:03.112329Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import re\n\ndef remove_recurring_characters(text):\n    # Use regular expression to find and replace recurring characters\n    cleaned_text = re.sub(r'\\n\\d+\\n+', r'\\n', text)\n    return cleaned_text\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:53:03.114990Z","iopub.execute_input":"2024-03-03T19:53:03.115291Z","iopub.status.idle":"2024-03-03T19:53:03.120627Z","shell.execute_reply.started":"2024-03-03T19:53:03.115265Z","shell.execute_reply":"2024-03-03T19:53:03.119562Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaders = [UnstructuredExcelLoader(f\"{books_path}/{i}\") for i in booklets]\ndocs_improved = []\nfor loader in loaders:\n  item = loader.load()\n  item[0].page_content = remove_recurring_characters(item[0].page_content)\n  docs_improved.extend(item)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:53:03.125625Z","iopub.execute_input":"2024-03-03T19:53:03.125957Z","iopub.status.idle":"2024-03-03T19:53:09.860606Z","shell.execute_reply.started":"2024-03-03T19:53:03.125931Z","shell.execute_reply":"2024-03-03T19:53:09.859758Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"##SPLITING###\n# Split\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 1024, #depends on input token size of llm\n    chunk_overlap = 128\n)\n\nsplits = text_splitter.split_documents(docs_improved)\n\nfrom langchain.text_splitter import CharacterTextSplitter\n\nc_text_splitter = CharacterTextSplitter(\n    separator=r\"\\d+\\.\\d+\",\n    chunk_size=1024,\n    chunk_overlap=128,\n    length_function=len,\n    is_separator_regex=True,\n    keep_separator = True\n)\n\nsplits_cts = c_text_splitter.split_documents(docs_improved)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:53:09.861706Z","iopub.execute_input":"2024-03-03T19:53:09.862438Z","iopub.status.idle":"2024-03-03T19:53:10.209862Z","shell.execute_reply.started":"2024-03-03T19:53:09.862409Z","shell.execute_reply":"2024-03-03T19:53:10.209092Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"splits.extend(splits_cts)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:53:10.210975Z","iopub.execute_input":"2024-03-03T19:53:10.211300Z","iopub.status.idle":"2024-03-03T19:53:10.215910Z","shell.execute_reply.started":"2024-03-03T19:53:10.211272Z","shell.execute_reply":"2024-03-03T19:53:10.214984Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"###VECTORE STORE SETUP","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:53:10.217304Z","iopub.execute_input":"2024-03-03T19:53:10.217572Z","iopub.status.idle":"2024-03-03T19:53:10.224887Z","shell.execute_reply.started":"2024-03-03T19:53:10.217548Z","shell.execute_reply":"2024-03-03T19:53:10.224086Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sentence_transformers.util import cos_sim\nmodel = SentenceTransformer('thenlper/gte-large')","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:53:10.225944Z","iopub.execute_input":"2024-03-03T19:53:10.226898Z","iopub.status.idle":"2024-03-03T19:54:30.837967Z","shell.execute_reply.started":"2024-03-03T19:53:10.226862Z","shell.execute_reply":"2024-03-03T19:54:30.837213Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a8f307a78c24e98b04d45886a964690"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"837e96885f504b53b53e1aaa8f0e3dff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/67.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f3b56c001094812a0861e0c538e7dbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56b870a76b0e4518b167fc070cae46a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61c28e5dc8154783a13b1a2d9ba3da23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"onnx/config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3053314111ee4325ac0d27e19a8caea3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.onnx:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4f8ff6cc57941a9bfeddcf75b4185a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"onnx/special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d4c5c02cd2e470dba407069841f7dda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"onnx/tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"194702ace071478e9b1fc252c54a99d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"onnx/tokenizer_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f93ada24fda64b31bd45c2f2b2686aa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"onnx/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a58ed8141e940a2836df6e7985405a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/670M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6593d4e0cdf44ebe8ff7fe4834e958dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79ed8654a2f04117af3a6fa172114a6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20087f01e31945098e631350cc4ce8e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0de020394d704a93869a9ce3aa89a68c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ed5a4cc4e8c4d68b2361fc83d986849"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe84276295de4d51999a674e573a95e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519f1cb41c9449a88117d2f05f7da2f4"}},"metadata":{}}]},{"cell_type":"code","source":"pg = [split.page_content for split in splits]\nembeddings = model.encode(pg)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:54:30.839115Z","iopub.execute_input":"2024-03-03T19:54:30.839370Z","iopub.status.idle":"2024-03-03T19:55:37.029589Z","shell.execute_reply.started":"2024-03-03T19:54:30.839347Z","shell.execute_reply":"2024-03-03T19:55:37.028785Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/65 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b574929e0f6443eb832d9663907766d4"}},"metadata":{}}]},{"cell_type":"code","source":"from langchain.vectorstores import Chroma\nfrom langchain_community.embeddings.sentence_transformer import (\n    SentenceTransformerEmbeddings,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:55:37.030950Z","iopub.execute_input":"2024-03-03T19:55:37.031421Z","iopub.status.idle":"2024-03-03T19:55:37.036329Z","shell.execute_reply.started":"2024-03-03T19:55:37.031385Z","shell.execute_reply":"2024-03-03T19:55:37.035380Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"persist_directory = 'docs/chroma/'\n!rm -rf ./docs/chroma","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:55:37.037527Z","iopub.execute_input":"2024-03-03T19:55:37.037828Z","iopub.status.idle":"2024-03-03T19:55:38.087104Z","shell.execute_reply.started":"2024-03-03T19:55:37.037803Z","shell.execute_reply":"2024-03-03T19:55:38.085858Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"###RETRIVIAL####\n# create the open-source embedding function\nembedding_function = SentenceTransformerEmbeddings(model_name=\"thenlper/gte-large\")\nvectordb = Chroma.from_documents(\n    documents=splits,\n    embedding=embedding_function,\n    persist_directory=persist_directory\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:55:38.088706Z","iopub.execute_input":"2024-03-03T19:55:38.089026Z","iopub.status.idle":"2024-03-03T19:56:52.809794Z","shell.execute_reply.started":"2024-03-03T19:55:38.088996Z","shell.execute_reply":"2024-03-03T19:56:52.808902Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#####RAG QUERY PIPELINE######","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:56:52.811198Z","iopub.execute_input":"2024-03-03T19:56:52.811506Z","iopub.status.idle":"2024-03-03T19:56:52.815785Z","shell.execute_reply.started":"2024-03-03T19:56:52.811478Z","shell.execute_reply":"2024-03-03T19:56:52.814767Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate\n\n# Build prompt\ntemplate = \"\"\"Use the following pieces of context to answer the question at the end. Use three sentences maximum. Keep the answer as concise as possible, whatever the amount of information in the context, keep your answers to a maximum of 3 sentences unless if quetion requires more sentences, like a list of something. also return the question as response if the answer is not in the context. \n{context}\nQuestion: {question}\nHelpful Answer:\"\"\"\nQA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n\n# Run chain\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 3, \"fetch_k\": 5}),\n    return_source_documents=True,\n    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:56:52.817031Z","iopub.execute_input":"2024-03-03T19:56:52.817336Z","iopub.status.idle":"2024-03-03T19:56:52.840648Z","shell.execute_reply.started":"2024-03-03T19:56:52.817312Z","shell.execute_reply":"2024-03-03T19:56:52.839912Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"question = \"what is the defination of unusual event\"\n\nresult = qa_chain({\"query\": question})","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:56:52.841701Z","iopub.execute_input":"2024-03-03T19:56:52.841979Z","iopub.status.idle":"2024-03-03T19:57:04.636057Z","shell.execute_reply.started":"2024-03-03T19:56:52.841954Z","shell.execute_reply":"2024-03-03T19:57:04.635253Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n  warn_deprecated(\n","output_type":"stream"}]},{"cell_type":"code","source":"print(result['result'])","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:57:04.637177Z","iopub.execute_input":"2024-03-03T19:57:04.637451Z","iopub.status.idle":"2024-03-03T19:57:04.642503Z","shell.execute_reply.started":"2024-03-03T19:57:04.637427Z","shell.execute_reply":"2024-03-03T19:57:04.641567Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":" The definition of an 'unusual event' in the context of Community Event-Based Surveillance (CEBS) can vary depending on the community and may be defined as one event or a cluster of events that are unusual for that specific community or during a certain time of year. For example, an unusual event could be a cluster of deaths from an unknown cause in the same household or adjacent households, or any person who becomes sick with symptoms that have not been seen before or not seen for a long time in their village.\n","output_type":"stream"}]},{"cell_type":"code","source":"result['source_documents']","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:57:04.643784Z","iopub.execute_input":"2024-03-03T19:57:04.644078Z","iopub.status.idle":"2024-03-03T19:57:04.653250Z","shell.execute_reply.started":"2024-03-03T19:57:04.644034Z","shell.execute_reply":"2024-03-03T19:57:04.652346Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[Document(page_content='Community Event-Based Surveillance (CEBS)\\n\\n\\nCEBS relies on reporting of unusual events and this is designed to rapidly identify whether something might be wrong in the community. Information may be incomplete, unconfirmed and may even be a rumour. The definition of an ‘unusual event’ will change from one community to another, and needs to be defined in each context. It can be one event, or a cluster of events, that may be unusual for a specific community or during a certain time of year. For example, an unusual event could be: “A cluster of deaths from an unknown cause in the same household or adjacent households”\\n\\n\\nCommunity-Indicator Based Surveillance (CIBS). This type of surveillance is used to identify/ report events based on agreed indicators (case definitions). Information from community can come from people who have already been oriented on the indicators and these include community volunteers, or any other representatives from community.', metadata={'source': '/kaggle/input/malawi-public-health-dataset/strengthening-health-systems-llm-challenge-for-integrated-disease-surveillance-and-response-in-malawi20240125-12750-1x85c8a/MWTGBookletsExcel/TG Booklet 1.xlsx'}),\n Document(page_content='from the same water source \\u2029any person that becomes sick with symptoms that have not seen before or not seen for a long time (e.g. an emerging infectious disease is suspected) \\u2029community member(s) become sick around the time that animals are sick or die in \\u2029their village \\u2029Sick or dead animals of unknown cause \\u2029\\u2029Health Facilities \\u2029The proposed definition for events to be reported by clinicians and health care facilities is: “Any outbreak of disease, OR any uncommon illness of potential public health concern, OR any infectious or infectious-like syndrome considered unusual by the clinician, based on frequency, circumstances of occurrence, clinical presentation, or severity”. \\u2029 \\u2029Any infectious or infectious-like syndrome considered unusual by the clinician based on: \\u2029Frequency- e.g., a sudden unexplained, significant increase in the number of patients, especially when it occurs outside the normal season. \\u2029Circumstances of occurrence – e.g., many patients coming from the same location or participating in similar', metadata={'source': '/kaggle/input/malawi-public-health-dataset/strengthening-health-systems-llm-challenge-for-integrated-disease-surveillance-and-response-in-malawi20240125-12750-1x85c8a/MWTGBookletsExcel/TG Booklet 6.xlsx'}),\n Document(page_content='Standard case definition\\ufdd0The proposed definition of a reportable event for laboratories is: \\u2029“Any situation considered unusual related to received samples (frequency, circumstances of occurrence or clinical description) OR test results (unexpected number of the same species/subspecies, strain type/subtype or antimicrobial resistance pattern, or failure/uncertainty in diagnostics)”.\\ufdd0Respond to alert threshold \\ufdd0If a single unexplained death or cluster of deaths or illness is suspected: \\u2029Report the suspected case or cases immediately using IDSR alert form \\u2029Begin active surveillance \\u2029Conduct a case-based investigation. \\u2029Notify events that cluster by person, place or time that are of concern.\\ufdd0Respond to action threshold \\ufdd0If a case is validated by district/County or Regional or National level will decide which actions to take. They may include the following response measures for routine outbreaks until Public Health Emergency RRT’s may be involved. See Section 6 of these IDSR guidelines. \\u2029Infection control', metadata={'source': '/kaggle/input/malawi-public-health-dataset/strengthening-health-systems-llm-challenge-for-integrated-disease-surveillance-and-response-in-malawi20240125-12750-1x85c8a/MWTGBookletsExcel/TG Booklet 6.xlsx'})]"},"metadata":{}}]},{"cell_type":"code","source":"###Question Parser\nimport pandas as pd\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:57:04.654405Z","iopub.execute_input":"2024-03-03T19:57:04.654689Z","iopub.status.idle":"2024-03-03T19:57:04.661343Z","shell.execute_reply.started":"2024-03-03T19:57:04.654655Z","shell.execute_reply":"2024-03-03T19:57:04.660622Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/malawi-public-health-dataset/strengthening-health-systems-llm-challenge-for-integrated-disease-surveillance-and-response-in-malawi20240125-12750-1x85c8a\"\ntrain = pd.read_csv(f\"{path}/Train.csv\")\ntrain","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:57:04.662538Z","iopub.execute_input":"2024-03-03T19:57:04.662835Z","iopub.status.idle":"2024-03-03T19:57:04.712694Z","shell.execute_reply.started":"2024-03-03T19:57:04.662810Z","shell.execute_reply":"2024-03-03T19:57:04.711794Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"        ID                                      Question Text  \\\n0     Q829  Compare the laboratory confirmation methods fo...   \n1     Q721  When should specimens be collected for Anthrax...   \n2     Q464  Which key information should be recorded durin...   \n3     Q449  Why is the District log of suspected outbreaks...   \n4       Q6  What do Community based surveillance strategie...   \n..     ...                                                ...   \n743   Q413  Which section of the guidelines provides a des...   \n744   Q626  Does MEF stand for an abbreviation in the TG, ...   \n745  Q1141  In what ways do the verification and documenta...   \n746   Q331  What role does the examination of burial cerem...   \n747   Q382  How do case fatality rates and attack rates di...   \n\n                                       Question Answer Reference Document  \\\n0    Chikungunya is confirmed using serological tes...       TG Booklet 6   \n1    Specimens should be collected during the vesic...       TG Booklet 6   \n2    During a register review, key information abou...       TG Booklet 3   \n3    The log includes information about response ac...       TG Booklet 3   \n4    Community-based surveillance strategies focus ...       TG Booklet 1   \n..                                                 ...                ...   \n743  Section 11.0 of these 3rd Edition Malawi IDSR ...       TG Booklet 3   \n744                        Medical Teams International       TG Booklet 6   \n745  In emergency contexts, verification and docume...       TG Booklet 5   \n746  Examining burial ceremonies helps identify pot...       TG Booklet 3   \n747  Case fatality rates focus on the proportion of...       TG Booklet 3   \n\n    Paragraph(s) Number                                           Keywords  \n0              154, 166  Laboratory Confirmation For Chikungunya Vs. Di...  \n1                   140  Anthrax Specimen Collection: Timing, Preparati...  \n2               439-440  Register Review, Key Information, Suspected Ca...  \n3                   412  District Log, Response Activities, Steps Taken...  \n4                    86  Community-based Surveillance Strategies, Ident...  \n..                  ...                                                ...  \n743                 376  Control Measures Description, Priority Disease...  \n744                 106                        Medical Teams International  \n745             105-106  Verification, Documentation, Early Warning, Em...  \n746                 287  Burial Ceremonies Examination, Exposure, Trans...  \n747            327, 328  Case Fatality Rates Vs. Attack Rates, Severity...  \n\n[748 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Question Text</th>\n      <th>Question Answer</th>\n      <th>Reference Document</th>\n      <th>Paragraph(s) Number</th>\n      <th>Keywords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q829</td>\n      <td>Compare the laboratory confirmation methods fo...</td>\n      <td>Chikungunya is confirmed using serological tes...</td>\n      <td>TG Booklet 6</td>\n      <td>154, 166</td>\n      <td>Laboratory Confirmation For Chikungunya Vs. Di...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q721</td>\n      <td>When should specimens be collected for Anthrax...</td>\n      <td>Specimens should be collected during the vesic...</td>\n      <td>TG Booklet 6</td>\n      <td>140</td>\n      <td>Anthrax Specimen Collection: Timing, Preparati...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q464</td>\n      <td>Which key information should be recorded durin...</td>\n      <td>During a register review, key information abou...</td>\n      <td>TG Booklet 3</td>\n      <td>439-440</td>\n      <td>Register Review, Key Information, Suspected Ca...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q449</td>\n      <td>Why is the District log of suspected outbreaks...</td>\n      <td>The log includes information about response ac...</td>\n      <td>TG Booklet 3</td>\n      <td>412</td>\n      <td>District Log, Response Activities, Steps Taken...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q6</td>\n      <td>What do Community based surveillance strategie...</td>\n      <td>Community-based surveillance strategies focus ...</td>\n      <td>TG Booklet 1</td>\n      <td>86</td>\n      <td>Community-based Surveillance Strategies, Ident...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>743</th>\n      <td>Q413</td>\n      <td>Which section of the guidelines provides a des...</td>\n      <td>Section 11.0 of these 3rd Edition Malawi IDSR ...</td>\n      <td>TG Booklet 3</td>\n      <td>376</td>\n      <td>Control Measures Description, Priority Disease...</td>\n    </tr>\n    <tr>\n      <th>744</th>\n      <td>Q626</td>\n      <td>Does MEF stand for an abbreviation in the TG, ...</td>\n      <td>Medical Teams International</td>\n      <td>TG Booklet 6</td>\n      <td>106</td>\n      <td>Medical Teams International</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>Q1141</td>\n      <td>In what ways do the verification and documenta...</td>\n      <td>In emergency contexts, verification and docume...</td>\n      <td>TG Booklet 5</td>\n      <td>105-106</td>\n      <td>Verification, Documentation, Early Warning, Em...</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>Q331</td>\n      <td>What role does the examination of burial cerem...</td>\n      <td>Examining burial ceremonies helps identify pot...</td>\n      <td>TG Booklet 3</td>\n      <td>287</td>\n      <td>Burial Ceremonies Examination, Exposure, Trans...</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>Q382</td>\n      <td>How do case fatality rates and attack rates di...</td>\n      <td>Case fatality rates focus on the proportion of...</td>\n      <td>TG Booklet 3</td>\n      <td>327, 328</td>\n      <td>Case Fatality Rates Vs. Attack Rates, Severity...</td>\n    </tr>\n  </tbody>\n</table>\n<p>748 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test = pd.read_csv(f\"{path}/Test.csv\")\ntest","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:57:04.713826Z","iopub.execute_input":"2024-03-03T19:57:04.714180Z","iopub.status.idle":"2024-03-03T19:57:04.731889Z","shell.execute_reply.started":"2024-03-03T19:57:04.714144Z","shell.execute_reply":"2024-03-03T19:57:04.731034Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"        ID                                      Question Text\n0       Q4          What is the definition of \"unusual event\"\n1       Q5        What is Community Based Surveillance (CBS)?\n2       Q9  What kind of training should members of VHC re...\n3      Q10        What is indicator based surveillance (IBS)?\n4      Q13                   What is Case based surveillance?\n..     ...                                                ...\n494  Q1229  Where should completeness be evaluated in the ...\n495  Q1230  Which dimensions of completeness are crucial i...\n496  Q1236  How can the completeness of case reporting be ...\n497  Q1239  Where should completeness and timeliness of re...\n498  Q1246  How does community-based surveillance contribu...\n\n[499 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Question Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q4</td>\n      <td>What is the definition of \"unusual event\"</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q5</td>\n      <td>What is Community Based Surveillance (CBS)?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q9</td>\n      <td>What kind of training should members of VHC re...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q10</td>\n      <td>What is indicator based surveillance (IBS)?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q13</td>\n      <td>What is Case based surveillance?</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>494</th>\n      <td>Q1229</td>\n      <td>Where should completeness be evaluated in the ...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>Q1230</td>\n      <td>Which dimensions of completeness are crucial i...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>Q1236</td>\n      <td>How can the completeness of case reporting be ...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>Q1239</td>\n      <td>Where should completeness and timeliness of re...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>Q1246</td>\n      <td>How does community-based surveillance contribu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>499 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"ss = pd.read_csv(f\"{path}/SampleSubmission.csv\")\nss","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:57:04.732904Z","iopub.execute_input":"2024-03-03T19:57:04.733203Z","iopub.status.idle":"2024-03-03T19:57:04.751606Z","shell.execute_reply.started":"2024-03-03T19:57:04.733178Z","shell.execute_reply":"2024-03-03T19:57:04.750773Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                             ID Target\n0                Q1000_keywords       \n1     Q1000_paragraph(s)_number       \n2         Q1000_question_answer       \n3      Q1000_reference_document       \n4                Q1002_keywords       \n...                         ...    ...\n1991    Q999_reference_document       \n1992                Q9_keywords       \n1993     Q9_paragraph(s)_number       \n1994         Q9_question_answer       \n1995      Q9_reference_document       \n\n[1996 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q1000_keywords</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q1000_paragraph(s)_number</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q1000_question_answer</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q1000_reference_document</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q1002_keywords</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1991</th>\n      <td>Q999_reference_document</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1992</th>\n      <td>Q9_keywords</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1993</th>\n      <td>Q9_paragraph(s)_number</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1994</th>\n      <td>Q9_question_answer</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>Q9_reference_document</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>1996 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_rag(query, qa_chain = qa_chain):\n    #print(f\"Query: {query}\\n\")\n    result = qa_chain({\"query\": question})\n    #print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n    #print(\"\\nResult: \", result)\n    return result['result']","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:57:04.756391Z","iopub.execute_input":"2024-03-03T19:57:04.756666Z","iopub.status.idle":"2024-03-03T19:57:04.761015Z","shell.execute_reply.started":"2024-03-03T19:57:04.756642Z","shell.execute_reply":"2024-03-03T19:57:04.760155Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"results = []\nsources = []\n\nfor question in tqdm(test[\"Question Text\"]):\n    try:\n        result = test_rag(question)\n        docs = vectordb.similarity_search(result)\n        source = docs[0].metadata['source'].split(\"/\")[-1]\n\n        results.append(result)\n        sources.append(source)\n    except:\n        \n        results.append(\"Error\")\n        sources.append(\"Error\") \n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:57:04.762036Z","iopub.execute_input":"2024-03-03T19:57:04.762353Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  2%|▏         | 8/499 [01:02<1:00:54,  7.44s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  2%|▏         | 9/499 [01:07<56:22,  6.90s/it]  /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  2%|▏         | 10/499 [01:18<1:04:45,  7.95s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  2%|▏         | 11/499 [01:29<1:12:03,  8.86s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  2%|▏         | 12/499 [01:37<1:09:43,  8.59s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nThis is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n  3%|▎         | 13/499 [06:08<11:55:16, 88.30s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  3%|▎         | 14/499 [06:12<8:27:28, 62.78s/it] /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  3%|▎         | 15/499 [06:23<6:19:56, 47.10s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  3%|▎         | 16/499 [06:27<4:35:01, 34.16s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  3%|▎         | 17/499 [06:37<3:35:52, 26.87s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  4%|▎         | 18/499 [06:42<2:42:10, 20.23s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  4%|▍         | 19/499 [06:52<2:16:51, 17.11s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  4%|▍         | 20/499 [06:58<1:52:07, 14.04s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  4%|▍         | 21/499 [07:02<1:26:23, 10.84s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  4%|▍         | 22/499 [07:06<1:10:55,  8.92s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  5%|▍         | 23/499 [07:11<1:00:10,  7.58s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  5%|▍         | 24/499 [07:21<1:05:44,  8.30s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  5%|▌         | 25/499 [07:26<58:44,  7.44s/it]  /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  5%|▌         | 26/499 [07:35<1:02:48,  7.97s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  5%|▌         | 27/499 [07:46<1:08:50,  8.75s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  6%|▌         | 28/499 [07:55<1:10:31,  8.98s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  6%|▌         | 29/499 [08:05<1:11:43,  9.16s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  6%|▌         | 30/499 [08:16<1:15:44,  9.69s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  6%|▌         | 31/499 [08:20<1:03:03,  8.08s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  6%|▋         | 32/499 [08:26<57:36,  7.40s/it]  /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  7%|▋         | 33/499 [08:33<56:00,  7.21s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  7%|▋         | 34/499 [08:46<1:09:37,  8.98s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  7%|▋         | 35/499 [08:55<1:09:21,  8.97s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  7%|▋         | 36/499 [09:01<1:02:43,  8.13s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  7%|▋         | 37/499 [09:11<1:05:50,  8.55s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  8%|▊         | 38/499 [09:18<1:03:27,  8.26s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  8%|▊         | 39/499 [09:23<56:13,  7.33s/it]  /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  8%|▊         | 40/499 [09:32<58:07,  7.60s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  8%|▊         | 41/499 [09:37<52:22,  6.86s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  8%|▊         | 42/499 [09:46<58:41,  7.71s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  9%|▊         | 43/499 [09:54<57:23,  7.55s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  9%|▉         | 44/499 [09:57<47:55,  6.32s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  9%|▉         | 45/499 [10:02<43:39,  5.77s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  9%|▉         | 46/499 [10:09<46:38,  6.18s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n  9%|▉         | 47/499 [10:13<42:40,  5.67s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 10%|▉         | 48/499 [10:21<47:42,  6.35s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 10%|▉         | 49/499 [10:29<50:43,  6.76s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 10%|█         | 50/499 [10:36<51:36,  6.90s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 10%|█         | 51/499 [10:44<53:28,  7.16s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 10%|█         | 52/499 [10:47<44:50,  6.02s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 11%|█         | 53/499 [10:55<48:07,  6.48s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 11%|█         | 54/499 [11:06<59:31,  8.03s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 11%|█         | 55/499 [11:18<1:08:02,  9.20s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 11%|█         | 56/499 [11:25<1:02:00,  8.40s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 11%|█▏        | 57/499 [11:35<1:06:18,  9.00s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 12%|█▏        | 58/499 [11:43<1:03:06,  8.59s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 12%|█▏        | 59/499 [11:48<54:35,  7.44s/it]  /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 12%|█▏        | 60/499 [11:59<1:03:08,  8.63s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 12%|█▏        | 61/499 [12:13<1:13:58, 10.13s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 12%|█▏        | 62/499 [12:28<1:24:56, 11.66s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 13%|█▎        | 63/499 [12:44<1:35:29, 13.14s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 13%|█▎        | 64/499 [12:52<1:24:09, 11.61s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 13%|█▎        | 65/499 [12:59<1:12:06,  9.97s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 13%|█▎        | 66/499 [13:24<1:45:50, 14.67s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 5020, but `max_length` is set to 4096. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n  warnings.warn(\n 13%|█▎        | 67/499 [13:34<1:34:29, 13.12s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 14%|█▎        | 68/499 [13:43<1:25:22, 11.89s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 14%|█▍        | 69/499 [13:52<1:19:52, 11.14s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 14%|█▍        | 70/499 [13:59<1:10:57,  9.93s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 14%|█▍        | 71/499 [14:05<1:00:55,  8.54s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 14%|█▍        | 72/499 [14:15<1:03:53,  8.98s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 15%|█▍        | 73/499 [14:21<57:51,  8.15s/it]  /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 16%|█▌        | 81/499 [15:40<1:00:21,  8.66s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 16%|█▋        | 82/499 [15:45<54:16,  7.81s/it]  /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 17%|█▋        | 83/499 [15:55<58:27,  8.43s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 17%|█▋        | 84/499 [16:13<1:17:36, 11.22s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 17%|█▋        | 85/499 [16:23<1:15:24, 10.93s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 17%|█▋        | 86/499 [16:34<1:15:29, 10.97s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 17%|█▋        | 87/499 [16:45<1:13:52, 10.76s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 18%|█▊        | 88/499 [16:53<1:08:49, 10.05s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 18%|█▊        | 89/499 [17:01<1:04:13,  9.40s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 18%|█▊        | 90/499 [17:07<56:25,  8.28s/it]  /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 18%|█▊        | 91/499 [17:16<58:41,  8.63s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 18%|█▊        | 92/499 [17:27<1:03:51,  9.41s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 19%|█▊        | 93/499 [17:36<1:02:33,  9.24s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 19%|█▉        | 94/499 [17:45<1:00:53,  9.02s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 19%|█▉        | 95/499 [18:38<2:30:29, 22.35s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 19%|█▉        | 96/499 [23:18<11:09:10, 99.63s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 19%|█▉        | 97/499 [23:33<8:17:34, 74.26s/it] /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 20%|█▉        | 98/499 [23:42<6:04:28, 54.54s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 20%|█▉        | 99/499 [23:52<4:34:39, 41.20s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 20%|██        | 100/499 [24:01<3:29:28, 31.50s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 20%|██        | 101/499 [24:12<2:47:59, 25.33s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 20%|██        | 102/499 [24:23<2:19:08, 21.03s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 21%|██        | 103/499 [28:51<10:27:53, 95.13s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 21%|██        | 104/499 [29:03<7:43:33, 70.41s/it] /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 21%|██        | 105/499 [29:17<5:49:45, 53.26s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 21%|██        | 106/499 [29:20<4:11:10, 38.35s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 21%|██▏       | 107/499 [29:26<3:06:31, 28.55s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 22%|██▏       | 108/499 [29:34<2:26:48, 22.53s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 22%|██▏       | 109/499 [29:44<2:02:21, 18.83s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 22%|██▏       | 110/499 [29:48<1:31:32, 14.12s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 22%|██▏       | 111/499 [30:04<1:34:56, 14.68s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 22%|██▏       | 112/499 [30:12<1:22:42, 12.82s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 23%|██▎       | 113/499 [30:26<1:25:09, 13.24s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 23%|██▎       | 114/499 [30:41<1:27:51, 13.69s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 23%|██▎       | 115/499 [30:54<1:27:06, 13.61s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 23%|██▎       | 116/499 [31:41<2:30:03, 23.51s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 23%|██▎       | 117/499 [31:47<1:56:08, 18.24s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 24%|██▎       | 118/499 [31:57<1:39:58, 15.74s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 24%|██▍       | 119/499 [32:04<1:22:34, 13.04s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 24%|██▍       | 120/499 [32:14<1:16:22, 12.09s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 24%|██▍       | 121/499 [32:24<1:12:54, 11.57s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 24%|██▍       | 122/499 [32:30<1:01:57,  9.86s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 25%|██▍       | 123/499 [32:38<58:33,  9.34s/it]  /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 25%|██▍       | 124/499 [32:45<53:24,  8.54s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 25%|██▌       | 125/499 [32:51<49:18,  7.91s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 25%|██▌       | 126/499 [33:05<59:45,  9.61s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 25%|██▌       | 127/499 [33:15<1:00:48,  9.81s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 26%|██▌       | 128/499 [33:25<1:01:47,  9.99s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 26%|██▌       | 129/499 [33:28<48:55,  7.93s/it]  /opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 26%|██▌       | 130/499 [33:37<49:58,  8.13s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 26%|██▋       | 131/499 [33:46<52:19,  8.53s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 26%|██▋       | 132/499 [33:53<47:40,  7.79s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 4541, but `max_length` is set to 4096. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n  warnings.warn(\n 27%|██▋       | 133/499 [34:04<54:58,  9.01s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 27%|██▋       | 134/499 [34:13<53:27,  8.79s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 27%|██▋       | 135/499 [34:18<47:30,  7.83s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 27%|██▋       | 136/499 [34:53<1:35:23, 15.77s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 27%|██▋       | 137/499 [35:13<1:44:16, 17.28s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 28%|██▊       | 138/499 [35:26<1:35:04, 15.80s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 28%|██▊       | 139/499 [35:34<1:21:40, 13.61s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 28%|██▊       | 140/499 [35:46<1:18:40, 13.15s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 28%|██▊       | 141/499 [35:56<1:12:04, 12.08s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 28%|██▊       | 142/499 [36:06<1:08:32, 11.52s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n 29%|██▊       | 143/499 [36:21<1:14:15, 12.51s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2024-03-03T22:07:44.577244Z","iopub.execute_input":"2024-03-03T22:07:44.578023Z","iopub.status.idle":"2024-03-03T22:07:44.902295Z","shell.execute_reply.started":"2024-03-03T22:07:44.577993Z","shell.execute_reply":"2024-03-03T22:07:44.901186Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"],"ename":"NameError","evalue":"name 'results' is not defined","output_type":"error"}]},{"cell_type":"code","source":"mysub = test.copy()\nmysub[\"Answers\"] = results\nmysub[\"Source files\"] = sources\nmysub.to_csv(\"full test.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set = pd.read_csv(\"full test.csv\")\ntest_set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom tqdm import tqdm\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\n\n\n# Download NLTK resources (run only once)\n#nltk.download('punkt')\n#nltk.download('stopwords')\n\ndef extract_keywords(provided_text):\n    # Tokenize the text\n    tokens = word_tokenize(provided_text)\n\n    # Convert tokens to lowercase\n    tokens = [token.lower() for token in tokens]\n\n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    filtered_tokens = [token.title() for token in tokens if token not in stop_words]\n\n    # Remove punctuation and non-alphabetic characters\n    keywords = [token for token in filtered_tokens if token.isalpha()]\n\n    # Remove duplicate keywords\n    unique_keywords = list(set(keywords))\n\n    return ', '.join(unique_keywords)\n\n\n\n\n\ndef find_matching_paragraphs(csv_filepath, text_to_check, threshold=0.9):\n    # Load the DataFrame\n    df = pd.read_excel(f\"{path}/MWTGBookletsExcel/{csv_filepath}\",names=[\"paragraph\", \"text\"])\n    df.fillna('', inplace=True)\n    # Concatenate all text from the 'text' column in the DataFrame\n    all_text = ' '.join(df['text'].astype(str).values.tolist())\n\n    # Combine the provided text and all text from the DataFrame\n    combined_text = [text_to_check, all_text]\n\n    # Initialize TfidfVectorizer\n    tfidf_vectorizer = TfidfVectorizer()\n\n    # Fit and transform the text in the DataFrame\n    tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'])\n\n    # Transform the provided text\n    provided_text_tfidf = tfidf_vectorizer.transform([text_to_check])\n\n    # Calculate cosine similarity between the provided text and each paragraph in the DataFrame\n    cosine_similarities = cosine_similarity(provided_text_tfidf, tfidf_matrix).flatten()\n\n    # Find paragraphs that meet or exceed the threshold\n    matching_paragraph_indices = [i for i, score in enumerate(cosine_similarities) if score >= threshold]\n\n    if matching_paragraph_indices:\n        # Get the corresponding paragraph numbers\n        matching_paragraph_numbers = df.iloc[matching_paragraph_indices]['paragraph'].tolist()\n        matching_paragraph_numbers = [str(int(i)) for i in matching_paragraph_numbers]\n        return ', '.join(matching_paragraph_numbers)\n    \n    else:\n        # If no paragraphs meet the threshold, fallback to selecting the paragraph with the highest similarity\n        closest_paragraph_index = cosine_similarities.argmax()\n        closest_paragraph_number = df.iloc[closest_paragraph_index]['paragraph']\n        return ', '.join([str(closest_paragraph_number)])  # Return as a list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set[\"Answers\"] = test_set[\"Answers\"].str.replace(\"\\n\", \"\")\ntest_set[\"Answers\"] = test_set[\"Answers\"].apply(lambda x: ' '.join([word for word in x.split() if len(word) <= 20]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ID = []\nTarget = []\n\nfor index, row in tqdm(test_set.iterrows(), total=len(test_set)):\n    if row[\"Answers\"]== \"Error\":\n        ID.append(row[\"ID\"]+\"_keywords\")\n        Target.append(extract_keywords(row[\"Question Text\"]))\n        ID.append(row[\"ID\"]+\"_paragraph(s)_number\")\n        Target.append(find_matching_paragraphs(\"TG Booklet 1.xlsx\", row[\"Question Text\"], threshold=0.9))\n        ID.append(row[\"ID\"]+\"_question_answer\")\n        Target.append(\" \")\n        ID.append(row[\"ID\"]+\"_reference_document\")\n        Target.append(\"TG Booklet 1\")\n        \n    else:\n        ID.append(row[\"ID\"]+\"_keywords\")\n        Target.append(extract_keywords(row[\"Answers\"]))\n        ID.append(row[\"ID\"]+\"_paragraph(s)_number\")\n        Target.append(find_matching_paragraphs(row[\"Source files\"], row[\"Answers\"], threshold=0.9))\n        ID.append(row[\"ID\"]+\"_question_answer\")\n        Target.append(row[\"Answers\"])\n        ID.append(row[\"ID\"]+\"_reference_document\")\n        Target.append(row[\"Source files\"].split(\".xlsx\")[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss = pd.read_csv(f\"{path}/SampleSubmission.csv\")\nss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss[\"ID\"] = ID\nss[\"Target\"] = Target\n\nss.to_csv(\"My Baseline submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}